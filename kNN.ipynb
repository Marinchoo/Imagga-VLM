{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b083020-a377-4d79-b4d7-0343104b4619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_input_features = params[\"num_input_features\"]\n",
    "        self.num_target_features = params[\"num_target_features\"]\n",
    "        self.dropout_rate=params[\"dropout_rate\"]\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.num_input_features, self.num_input_features*4)\n",
    "        self.fc2 = nn.Linear(self.num_input_features*4, self.num_input_features*2)\n",
    "        self.fc3 = nn.Linear(self.num_input_features*2, self.num_input_features)\n",
    "        self.fc4 = nn.Linear(self.num_input_features, self.num_target_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x=F.dropout(x, self.dropout_rate)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x=F.dropout(x, self.dropout_rate)\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x=F.dropout(x, self.dropout_rate)\n",
    "        output = self.fc4(x)       \n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e24fab-9ac5-47f8-b058-19f00af99cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(params['model'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a7961-e557-400e-855d-b4571f9889da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(MLP2, self).__init__()\n",
    "        self.num_input_features = params[\"num_input_features\"]\n",
    "        self.num_target_features = params[\"num_target_features\"]\n",
    "        self.dropout_rate = params[\"dropout_rate\"]\n",
    "        self.num_layers = params[\"num_layers\"]\n",
    "        \n",
    "        layers = []\n",
    "        input_features = self.num_input_features\n",
    "        increasing_layers = self.num_layers // 2\n",
    "        \n",
    "        # Increasing part\n",
    "        for i in range(increasing_layers):\n",
    "            output_features = input_features * 2\n",
    "            layers.append(nn.Linear(input_features, output_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout_rate))\n",
    "            input_features = output_features\n",
    "        \n",
    "        # Decreasing part\n",
    "        for i in range(self.num_layers - increasing_layers - 1):\n",
    "            output_features = input_features // 2\n",
    "            layers.append(nn.Linear(input_features, output_features))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(self.dropout_rate))\n",
    "            input_features = output_features\n",
    "        \n",
    "        # Final layer\n",
    "        layers.append(nn.Linear(input_features, self.num_target_features))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a33a32-58cd-4643-a3de-0997b5b60cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "batch_size = 16\n",
    "summary(model2, input_size=(1, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "647efc75-b8ad-483e-80a0-b350f0ead94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output shapes:\n",
      "Linear: torch.Size([16, 2])\n",
      "Small NN: torch.Size([16, 2])\n",
      "Four-layer MLP: torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# from torchinfo import summary\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== 1. Dataset setup =====\n",
    "data_dir = Path(\".\")  # current dir containing train/ and test/\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir / \"train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(data_dir / \"test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "input_size = 64 * 64 * 3  # flattened image size\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ===== 2. Model definitions =====\n",
    "# 1) Linear model (no encoder)\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten\n",
    "        return self.fc(x)\n",
    "\n",
    "# 2) Small Neural Net (2 layers)\n",
    "class SmallNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# 3) Four-layer MLP (your original MLP)\n",
    "class MLP4(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "        self.dropout_rate = dropout_rate\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout_rate)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, self.dropout_rate)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, self.dropout_rate)\n",
    "        return self.fc4(x)\n",
    "\n",
    "\n",
    "# ===== 3. Instantiate models =====\n",
    "model1 = LinearModel(input_size, num_classes).to(device)\n",
    "model2 = SmallNN(input_size, num_classes).to(device)\n",
    "model3 = MLP4(input_size, num_classes).to(device)\n",
    "\n",
    "# ===== 4. Summaries =====\n",
    "# print(\"=== Linear Model ===\")\n",
    "# summary(model1, input_size=(1, 3, 64, 64))\n",
    "# print(\"\\n=== Small NN ===\")\n",
    "# summary(model2, input_size=(1, 3, 64, 64))\n",
    "# print(\"\\n=== Four-layer MLP ===\")\n",
    "# summary(model3, input_size=(1, 3, 64, 64))\n",
    "\n",
    "# ===== 5. Quick forward pass =====\n",
    "sample_data, _ = next(iter(train_loader))\n",
    "sample_data = sample_data.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out1 = model1(sample_data)\n",
    "    out2 = model2(sample_data)\n",
    "    out3 = model3(sample_data)\n",
    "\n",
    "print(\"\\nOutput shapes:\")\n",
    "print(\"Linear:\", out1.shape)\n",
    "print(\"Small NN:\", out2.shape)\n",
    "print(\"Four-layer MLP:\", out3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "738b9f8d-ea8d-4ece-9b22-c2d934deaada",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear...\n",
      "Epoch 1/5 - Train loss: 0.8502, Train acc: 0.6105 | Test loss: 1.8078, Test acc: 0.5083\n",
      "Epoch 2/5 - Train loss: 0.8570, Train acc: 0.6095 | Test loss: 0.9808, Test acc: 0.5516\n",
      "Epoch 3/5 - Train loss: 0.8654, Train acc: 0.6111 | Test loss: 0.7352, Test acc: 0.6149\n",
      "Epoch 4/5 - Train loss: 0.8510, Train acc: 0.6131 | Test loss: 1.1253, Test acc: 0.5545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:27:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/12 16:27:02 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.8642, Train acc: 0.6088 | Test loss: 0.8507, Test acc: 0.5780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:27:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/12 16:27:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SmallNN...\n",
      "Epoch 1/5 - Train loss: 0.5509, Train acc: 0.7151 | Test loss: 0.5256, Test acc: 0.7334\n",
      "Epoch 2/5 - Train loss: 0.5371, Train acc: 0.7254 | Test loss: 0.5419, Test acc: 0.7255\n",
      "Epoch 3/5 - Train loss: 0.5307, Train acc: 0.7308 | Test loss: 0.5434, Test acc: 0.7182\n",
      "Epoch 4/5 - Train loss: 0.5275, Train acc: 0.7328 | Test loss: 0.5331, Test acc: 0.7302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:29:35 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/12 16:29:35 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.5241, Train acc: 0.7370 | Test loss: 0.5609, Test acc: 0.7027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:29:37 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/12 16:29:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP4...\n",
      "Epoch 1/5 - Train loss: 0.6333, Train acc: 0.6273 | Test loss: 0.6203, Test acc: 0.6262\n",
      "Epoch 2/5 - Train loss: 0.6086, Train acc: 0.6595 | Test loss: 0.6054, Test acc: 0.6585\n",
      "Epoch 3/5 - Train loss: 0.6011, Train acc: 0.6674 | Test loss: 0.5863, Test acc: 0.6832\n",
      "Epoch 4/5 - Train loss: 0.6013, Train acc: 0.6625 | Test loss: 0.6054, Test acc: 0.6474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:32:33 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/12 16:32:33 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.6051, Train acc: 0.6561 | Test loss: 0.6033, Test acc: 0.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:32:36 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/12 16:32:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "def eval_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models = {\n",
    "    \"Linear\": model1,\n",
    "    \"SmallNN\": model2,\n",
    "    \"MLP4\": model3\n",
    "}\n",
    "\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            test_loss, test_acc = eval_model(model, test_loader, criterion, device)\n",
    "\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} | \"\n",
    "                f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "        example_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "        mlflow.pytorch.log_model(model, artifact_path=\"models\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6705fc-2a97-4dae-a270-ed114104d1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenBLAS warning: precompiled NUM_THREADS exceeded, adding auxiliary array for thread metadata.\n",
      "To avoid this warning, please rebuild your copy of OpenBLAS with a larger NUM_THREADS setting\n",
      "or set the environment variable OPENBLAS_NUM_THREADS to 64 or lower\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "data_dir = Path(\".\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir / \"train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(data_dir / \"test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a frozen encoder flatten\n",
    "class FrozenEncoder(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)  # flatten\n",
    "\n",
    "encoder = FrozenEncoder().to(device)\n",
    "encoder.eval()  # freeze, no training\n",
    "\n",
    "# extract features for train and test\n",
    "def extract_features(loader):\n",
    "    features, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = encoder(imgs)          # frozen features\n",
    "            features.append(feats.cpu().numpy())\n",
    "            labels.append(lbls.numpy())\n",
    "    return np.vstack(features), np.hstack(labels)\n",
    "\n",
    "X_train, y_train = extract_features(train_loader)\n",
    "X_test, y_test = extract_features(test_loader)\n",
    "\n",
    "# train a simple KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"KNN (frozen encoder) accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8947e05-76d5-4521-848f-97479b458438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear...\n",
      "Epoch 1/5 - Train loss: 0.8695, Train acc: 0.5955 | Test loss: 1.6715, Test acc: 0.5184\n",
      "Epoch 2/5 - Train loss: 0.8710, Train acc: 0.6042 | Test loss: 1.1568, Test acc: 0.5459\n",
      "Epoch 3/5 - Train loss: 0.8638, Train acc: 0.6077 | Test loss: 0.7346, Test acc: 0.6090\n",
      "Epoch 4/5 - Train loss: 0.8761, Train acc: 0.6088 | Test loss: 0.6707, Test acc: 0.6509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:39:50 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/12 16:39:50 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.8704, Train acc: 0.6075 | Test loss: 1.6863, Test acc: 0.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:39:53 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/12 16:39:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SmallNN...\n",
      "Epoch 1/5 - Train loss: 0.6027, Train acc: 0.6665 | Test loss: 0.5645, Test acc: 0.7042\n",
      "Epoch 2/5 - Train loss: 0.5605, Train acc: 0.7058 | Test loss: 0.5485, Test acc: 0.7188\n",
      "Epoch 3/5 - Train loss: 0.5535, Train acc: 0.7127 | Test loss: 0.5447, Test acc: 0.7184\n",
      "Epoch 4/5 - Train loss: 0.5476, Train acc: 0.7187 | Test loss: 0.5440, Test acc: 0.7149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:42:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/12 16:42:23 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.5462, Train acc: 0.7201 | Test loss: 0.5333, Test acc: 0.7282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:42:26 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/12 16:42:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP4...\n",
      "Epoch 1/5 - Train loss: 0.6540, Train acc: 0.6046 | Test loss: 0.6351, Test acc: 0.6240\n",
      "Epoch 2/5 - Train loss: 0.6412, Train acc: 0.6266 | Test loss: 0.6169, Test acc: 0.6536\n",
      "Epoch 3/5 - Train loss: 0.6431, Train acc: 0.6181 | Test loss: 0.6278, Test acc: 0.6371\n",
      "Epoch 4/5 - Train loss: 0.6421, Train acc: 0.6213 | Test loss: 0.6425, Test acc: 0.6340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:45:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/12 16:45:22 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.6446, Train acc: 0.6134 | Test loss: 0.6345, Test acc: 0.6239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/12 16:45:25 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/12 16:45:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Training complete. Plots saved as 'loss_plot.png' and 'accuracy_plot.png'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset setup\n",
    "data_dir = Path(\".\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir / \"train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(data_dir / \"test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "input_size = 64 * 64 * 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# models\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class SmallNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "class MLP4(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "        self.dropout_rate = dropout_rate\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, self.dropout_rate, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, self.dropout_rate, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, self.dropout_rate, training=self.training)\n",
    "        return self.fc4(x)\n",
    "\n",
    "# training helpers\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def eval_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# Setup\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models = {\n",
    "    \"Linear\": LinearModel(input_size, num_classes).to(device),\n",
    "    \"SmallNN\": SmallNN(input_size, num_classes).to(device),\n",
    "    \"MLP4\": MLP4(input_size, num_classes).to(device)\n",
    "}\n",
    "\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "results = {}\n",
    "\n",
    "# training loop\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "        train_losses, test_losses = [], []\n",
    "        train_accs, test_accs = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            test_loss, test_acc = eval_model(model, test_loader, criterion, device)\n",
    "\n",
    "            # Save metrics\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            test_accs.append(test_acc)\n",
    "\n",
    "            # Log to MLflow\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} | \"\n",
    "                f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "        example_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "        mlflow.pytorch.log_model(model, artifact_path=\"models\")\n",
    "\n",
    "        # Save results for plotting later\n",
    "        results[name] = {\n",
    "            \"train_loss\": train_losses,\n",
    "            \"test_loss\": test_losses,\n",
    "            \"train_acc\": train_accs,\n",
    "            \"test_acc\": test_accs\n",
    "        }\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(10,5))\n",
    "for name, data in results.items():\n",
    "    plt.plot(data[\"train_loss\"], label=f\"{name} Train Loss\")\n",
    "    plt.plot(data[\"test_loss\"], label=f\"{name} Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"loss_plot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for name, data in results.items():\n",
    "    plt.plot(data[\"train_acc\"], label=f\"{name} Train Acc\")\n",
    "    plt.plot(data[\"test_acc\"], label=f\"{name} Test Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"accuracy_plot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTraining complete. Plots saved as 'loss_plot.png' and 'accuracy_plot.png'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c21024-9aea-4a1b-832a-631af72add06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Linear...\n",
      "Epoch 1/5 - Train loss: 0.8826, Train acc: 0.5966 | Test loss: 1.0929, Test acc: 0.5483\n",
      "Epoch 2/5 - Train loss: 0.8762, Train acc: 0.6012 | Test loss: 0.7277, Test acc: 0.6072\n",
      "Epoch 3/5 - Train loss: 0.8931, Train acc: 0.6056 | Test loss: 0.7036, Test acc: 0.6392\n",
      "Epoch 4/5 - Train loss: 0.8650, Train acc: 0.6061 | Test loss: 1.8998, Test acc: 0.5086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:52:27 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/19 11:52:27 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.8657, Train acc: 0.6088 | Test loss: 0.7520, Test acc: 0.6449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:52:31 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/19 11:52:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SmallNN...\n",
      "Epoch 1/5 - Train loss: 0.6059, Train acc: 0.6672 | Test loss: 0.5437, Test acc: 0.7167\n",
      "Epoch 2/5 - Train loss: 0.5535, Train acc: 0.7143 | Test loss: 0.5353, Test acc: 0.7238\n",
      "Epoch 3/5 - Train loss: 0.5397, Train acc: 0.7248 | Test loss: 0.5242, Test acc: 0.7358\n",
      "Epoch 4/5 - Train loss: 0.5303, Train acc: 0.7322 | Test loss: 0.5364, Test acc: 0.7179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:55:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/19 11:55:02 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.5244, Train acc: 0.7352 | Test loss: 0.5406, Test acc: 0.7230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:55:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/19 11:55:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training MLP4_BN...\n",
      "Epoch 1/5 - Train loss: 0.5465, Train acc: 0.7223 | Test loss: 0.4705, Test acc: 0.7766\n",
      "Epoch 2/5 - Train loss: 0.5004, Train acc: 0.7562 | Test loss: 0.4432, Test acc: 0.7972\n",
      "Epoch 3/5 - Train loss: 0.4757, Train acc: 0.7752 | Test loss: 0.4157, Test acc: 0.8080\n",
      "Epoch 4/5 - Train loss: 0.4574, Train acc: 0.7849 | Test loss: 0.4368, Test acc: 0.7927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:58:11 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/08/19 11:58:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train loss: 0.4439, Train acc: 0.7928 | Test loss: 0.3962, Test acc: 0.8210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 11:58:14 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu121) contains a local version label (+cu121). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "\u001b[31m2025/08/19 11:58:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete. Plots saved as 'loss_plot.png' and 'accuracy_plot.png'.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dataset setup\n",
    "data_dir = Path(\".\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir / \"train\", transform=transform)\n",
    "test_dataset = datasets.ImageFolder(data_dir / \"test\", transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "input_size = 64 * 64 * 3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# models\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class SmallNN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, hidden_size=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "class MLP4_BN(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout_rate=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        self.bn1 = nn.BatchNorm1d(1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc4 = nn.Linear(256, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.bn1(self.fc1(x))))\n",
    "        x = self.dropout(F.relu(self.bn2(self.fc2(x))))\n",
    "        x = self.dropout(F.relu(self.bn3(self.fc3(x))))\n",
    "        return self.fc4(x)\n",
    "\n",
    "# training helpers\n",
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "def eval_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return running_loss / total, correct / total\n",
    "\n",
    "# Setup\n",
    "epochs = 5\n",
    "learning_rate = 1e-3\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "models = {\n",
    "    \"Linear\": LinearModel(input_size, num_classes).to(device),\n",
    "    \"SmallNN\": SmallNN(input_size, num_classes).to(device),\n",
    "    \"MLP4_BN\": MLP4_BN(input_size, num_classes).to(device)\n",
    "}\n",
    "\n",
    "if mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "\n",
    "results = {}\n",
    "\n",
    "# training loop\n",
    "for name, model in models.items():\n",
    "    with mlflow.start_run(run_name=name):\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        mlflow.log_param(\"model_name\", name)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "\n",
    "        train_losses, test_losses = [], []\n",
    "        train_accs, test_accs = [], []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            test_loss, test_acc = eval_model(model, test_loader, criterion, device)\n",
    "\n",
    "            # Save metrics\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            train_accs.append(train_acc)\n",
    "            test_accs.append(test_acc)\n",
    "\n",
    "            # Log to MLflow\n",
    "            mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "            mlflow.log_metric(\"train_accuracy\", train_acc, step=epoch)\n",
    "            mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "            mlflow.log_metric(\"test_accuracy\", test_acc, step=epoch)\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{epochs} - \"\n",
    "                f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} | \"\n",
    "                f\"Test loss: {test_loss:.4f}, Test acc: {test_acc:.4f}\"\n",
    "            )\n",
    "\n",
    "        example_input = torch.randn(1, 3, 64, 64).to(device)\n",
    "        mlflow.pytorch.log_model(model, artifact_path=\"models\")\n",
    "\n",
    "        # Save results for plotting later\n",
    "        results[name] = {\n",
    "            \"train_loss\": train_losses,\n",
    "            \"test_loss\": test_losses,\n",
    "            \"train_acc\": train_accs,\n",
    "            \"test_acc\": test_accs\n",
    "        }\n",
    "\n",
    "# plot results\n",
    "plt.figure(figsize=(10,5))\n",
    "for name, data in results.items():\n",
    "    plt.plot(data[\"train_loss\"], label=f\"{name} Train Loss\")\n",
    "    plt.plot(data[\"test_loss\"], label=f\"{name} Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"loss_plot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for name, data in results.items():\n",
    "    plt.plot(data[\"train_acc\"], label=f\"{name} Train Acc\")\n",
    "    plt.plot(data[\"test_acc\"], label=f\"{name} Test Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"accuracy_plot.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nTraining complete. Plots saved as 'loss_plot.png' and 'accuracy_plot.png'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285879c1-f204-4e1b-917c-03c82fad7be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
